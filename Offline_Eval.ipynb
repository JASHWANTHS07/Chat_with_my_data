{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T09:04:24.651886Z",
     "start_time": "2024-07-30T09:02:24.522970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "from eval_metrics import IOGuards, TextStat, ComparisonMetrics\n",
    "from eval_metrics import TraditionalPipelines\n",
    "import evaluate\n",
    "\n",
    "# Initialize the evaluation components\n",
    "guard = IOGuards()\n",
    "stat = TextStat()\n",
    "comp = ComparisonMetrics()\n",
    "\n",
    "# Initialize the traditional NLP pipelines\n",
    "trad_pipelines = TraditionalPipelines()\n",
    "\n",
    "# Load the correct model configuration and model\n",
    "config = AutoConfig.from_pretrained('vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained('vectara/hallucination_evaluation_model', config=config, trust_remote_code=True)\n",
    "\n",
    "# Load the BLEURT model with a larger sequence length\n",
    "bleurt = evaluate.load('bleurt', 'bleurt-large-512')\n",
    "\n",
    "def evaluate_all(query, context_lis, response):\n",
    "    \"\"\"\n",
    "    Evaluate the quality and safety of the response given a query and context.\n",
    "    \"\"\"\n",
    "    context = \"\\n\".join(context_lis)\n",
    "\n",
    "    RESULT = {}\n",
    "\n",
    "    # Guards and Safety Checks\n",
    "    RESULT[\"guards\"] = {\n",
    "        \"query_injection\": guard.prompt_injection_classif(query),\n",
    "        \"context_injection\": guard.prompt_injection_classif(context),\n",
    "        \"query_bias\": guard.bias(query),\n",
    "        \"context_bias\": guard.bias(context),\n",
    "        \"response_bias\": guard.bias(response),\n",
    "        \"query_regex\": guard.detect_pattern(query),\n",
    "        \"context_regex\": guard.detect_pattern(context),\n",
    "        \"response_regex\": guard.detect_pattern(response),\n",
    "        \"query_toxicity\": guard.toxicity(query),\n",
    "        \"context_toxicity\": guard.toxicity(context),\n",
    "        \"response_toxicity\": guard.toxicity(response),\n",
    "        \"query_sentiment\": guard.sentiment(query),\n",
    "        \"query_polarity\": guard.polarity(query),\n",
    "        \"context_polarity\": guard.polarity(context), \n",
    "        \"response_polarity\": guard.polarity(response), \n",
    "        \"query_response_hallucination\": comp.hallucinations(query, response),\n",
    "        \"context_response_hallucination\": comp.hallucinations(context, response),\n",
    "        \"query_response_contradiction\": comp.contradiction(query, response),\n",
    "        \"context_response_contradiction\": comp.contradiction(context, response),\n",
    "    }\n",
    "\n",
    "    # Harmful content and refusal analysis\n",
    "    RESULT[\"guards\"].update(guard.harmful_refusal_guards(query, context, response))\n",
    "\n",
    "    # Reference-Based Metrics\n",
    "    RESULT[\"reference_based_metrics\"] = {}\n",
    "    for key, val in comp.ref_focussed_metrics(query, response).items():\n",
    "        RESULT[\"reference_based_metrics\"][f\"query_response_{key}\"] = val\n",
    "\n",
    "    for key, val in comp.ref_focussed_metrics(context, response).items():\n",
    "        RESULT[\"reference_based_metrics\"][f\"context_response_{key}\"] = val\n",
    "    \n",
    "    # String Similarity Metrics\n",
    "    RESULT[\"string_similarities\"] = {}\n",
    "    for key, val in comp.string_similarity(query, response).items():\n",
    "        RESULT[\"string_similarities\"][f\"query_response_{key}\"] = val\n",
    "\n",
    "    for key, val in comp.string_similarity(context, response).items():\n",
    "        RESULT[\"string_similarities\"][f\"context_response_{key}\"] = val\n",
    "    \n",
    "    # Text Statistics\n",
    "    RESULT[\"response_text_stats\"] = {}\n",
    "    for key, val in stat.calculate_text_stat(response).items():\n",
    "        RESULT[\"response_text_stats\"][f\"result_{key}\"] = val\n",
    "\n",
    "    # Summarization\n",
    "    summary_text = trad_pipelines.Summarizer(response, model_name=\"t5\")\n",
    "    RESULT[\"summarizer_summary\"] = summary_text\n",
    "\n",
    "    # POS and NER\n",
    "    pos_result = trad_pipelines.POS(response)\n",
    "    ner_result = trad_pipelines.NER(response)\n",
    "    RESULT[\"POS\"] = pos_result\n",
    "    RESULT[\"NER\"] = ner_result\n",
    "    \n",
    "    return RESULT\n",
    "\n",
    "# Example usage\n",
    "query = \"Everyone is a terrorist\"\n",
    "context_lis = [\"Eminem is the white legend\", \"Trump's a bitch\"]\n",
    "response = \"There is no answer to that. These questions and context are bad\"\n",
    "\n",
    "evaluation_result = evaluate_all(query, context_lis, response)\n",
    "\n",
    "# Display the evaluation results\n",
    "import pprint\n",
    "pprint.pprint(evaluation_result)\n"
   ],
   "id": "4288027706f803fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Github_Projects\\ChatwithMyData\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 14:33:09.592 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run E:\\Github_Projects\\ChatwithMyData\\.venv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Bling\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Github_Projects\\ChatwithMyData\\.venv\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at d4data/bias-detection-model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Github_Projects\\ChatwithMyData\\.venv\\lib\\site-packages\\bleurt\\score.py:160: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Bling\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\a6efdcb912e038fca582570be0606d0ef6237a18b82cde00fe064f0c620e1f06\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "WARNING:tensorflow:From E:\\Github_Projects\\ChatwithMyData\\.venv\\lib\\site-packages\\bleurt\\lib\\bert_tokenization.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bling\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bling\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Bling\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "E:\\Github_Projects\\ChatwithMyData\\.venv\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Bling\\.cache\\huggingface\\metrics\\bleurt\\bleurt-large-512\\downloads\\extracted\\fb1fde3a4c34adc8df0dc83962aea738ecfc537a61ee99b9f3f5b9d8beb530e9\\bleurt-large-512.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Bling\\.cache\\huggingface\\metrics\\bleurt\\bleurt-large-512\\downloads\\extracted\\fb1fde3a4c34adc8df0dc83962aea738ecfc537a61ee99b9f3f5b9d8beb530e9\\bleurt-large-512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 30, but your input_length is only 16. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NER': [],\n",
      " 'POS': [{'end': 5,\n",
      "          'entity': 'PRON',\n",
      "          'index': 1,\n",
      "          'score': 0.9994524,\n",
      "          'start': 0,\n",
      "          'word': 'there'},\n",
      "         {'end': 8,\n",
      "          'entity': 'VERB',\n",
      "          'index': 2,\n",
      "          'score': 0.9990658,\n",
      "          'start': 6,\n",
      "          'word': 'is'},\n",
      "         {'end': 11,\n",
      "          'entity': 'DET',\n",
      "          'index': 3,\n",
      "          'score': 0.999286,\n",
      "          'start': 9,\n",
      "          'word': 'no'},\n",
      "         {'end': 18,\n",
      "          'entity': 'NOUN',\n",
      "          'index': 4,\n",
      "          'score': 0.99812347,\n",
      "          'start': 12,\n",
      "          'word': 'answer'},\n",
      "         {'end': 21,\n",
      "          'entity': 'ADP',\n",
      "          'index': 5,\n",
      "          'score': 0.99938786,\n",
      "          'start': 19,\n",
      "          'word': 'to'},\n",
      "         {'end': 26,\n",
      "          'entity': 'PRON',\n",
      "          'index': 6,\n",
      "          'score': 0.9989139,\n",
      "          'start': 22,\n",
      "          'word': 'that'},\n",
      "         {'end': 27,\n",
      "          'entity': 'PUNCT',\n",
      "          'index': 7,\n",
      "          'score': 0.99966395,\n",
      "          'start': 26,\n",
      "          'word': '.'},\n",
      "         {'end': 33,\n",
      "          'entity': 'DET',\n",
      "          'index': 8,\n",
      "          'score': 0.99930954,\n",
      "          'start': 28,\n",
      "          'word': 'these'},\n",
      "         {'end': 43,\n",
      "          'entity': 'NOUN',\n",
      "          'index': 9,\n",
      "          'score': 0.99911064,\n",
      "          'start': 34,\n",
      "          'word': 'questions'},\n",
      "         {'end': 47,\n",
      "          'entity': 'CCONJ',\n",
      "          'index': 10,\n",
      "          'score': 0.99889094,\n",
      "          'start': 44,\n",
      "          'word': 'and'},\n",
      "         {'end': 55,\n",
      "          'entity': 'NOUN',\n",
      "          'index': 11,\n",
      "          'score': 0.999198,\n",
      "          'start': 48,\n",
      "          'word': 'context'},\n",
      "         {'end': 59,\n",
      "          'entity': 'AUX',\n",
      "          'index': 12,\n",
      "          'score': 0.99636614,\n",
      "          'start': 56,\n",
      "          'word': 'are'},\n",
      "         {'end': 63,\n",
      "          'entity': 'ADJ',\n",
      "          'index': 13,\n",
      "          'score': 0.99881315,\n",
      "          'start': 60,\n",
      "          'word': 'bad'}],\n",
      " 'guards': {'context_bias': [{'label': 'Non-biased',\n",
      "                              'score': 0.585870623588562}],\n",
      "            'context_injection': [{'label': 'SAFE',\n",
      "                                   'score': 0.9999991655349731}],\n",
      "            'context_polarity': [{'negative': 0.96,\n",
      "                                  'neutral': 0.01,\n",
      "                                  'other': 0.03,\n",
      "                                  'positive': 0.0}],\n",
      "            'context_regex': {},\n",
      "            'context_response_contradiction': {'contradiction': 10.0,\n",
      "                                               'entailment': 10.3,\n",
      "                                               'neutral': 79.7},\n",
      "            'context_response_hallucination': tensor([0.1319]),\n",
      "            'context_toxicity': [{'label': 'toxic',\n",
      "                                  'score': 0.9640267491340637}],\n",
      "            'harmful_context': False,\n",
      "            'harmful_query': False,\n",
      "            'harmful_response': False,\n",
      "            'query_bias': [{'label': 'Biased', 'score': 0.6330747008323669}],\n",
      "            'query_injection': [{'label': 'SAFE', 'score': 0.9999986886978149}],\n",
      "            'query_polarity': [{'negative': 0.98,\n",
      "                                'neutral': 0.01,\n",
      "                                'other': 0.01,\n",
      "                                'positive': 0.0}],\n",
      "            'query_regex': {},\n",
      "            'query_response_contradiction': {'contradiction': 0.7,\n",
      "                                             'entailment': 1.5,\n",
      "                                             'neutral': 97.8},\n",
      "            'query_response_hallucination': tensor([0.0323]),\n",
      "            'query_sentiment': {'compound': -0.6908,\n",
      "                                'neg': 0.701,\n",
      "                                'neu': 0.299,\n",
      "                                'pos': 0.0},\n",
      "            'query_toxicity': [{'label': 'toxic', 'score': 0.9225955009460449}],\n",
      "            'refusal_response': False,\n",
      "            'response_bias': [{'label': 'Biased', 'score': 0.5588836073875427}],\n",
      "            'response_polarity': [{'negative': 0.7,\n",
      "                                   'neutral': 0.1,\n",
      "                                   'other': 0.19,\n",
      "                                   'positive': 0.02}],\n",
      "            'response_regex': {},\n",
      "            'response_toxicity': [{'label': 'non-toxic',\n",
      "                                   'score': 0.9988303780555725}]},\n",
      " 'reference_based_metrics': {'context_response_bertscore': {'f1': [0.844143271446228],\n",
      "                                                            'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.43.2)',\n",
      "                                                            'precision': [0.8416609168052673],\n",
      "                                                            'recall': [0.8466403484344482]},\n",
      "                             'context_response_bleu': {'bleu': 0.0,\n",
      "                                                       'brevity_penalty': 1.0,\n",
      "                                                       'length_ratio': 1.625,\n",
      "                                                       'precisions': [0.07692307692307693,\n",
      "                                                                      0.0,\n",
      "                                                                      0.0,\n",
      "                                                                      0.0],\n",
      "                                                       'reference_length': 8,\n",
      "                                                       'translation_length': 13},\n",
      "                             'context_response_bleurt': {'scores': [-1.3652902841567993]},\n",
      "                             'context_response_meteor': {'meteor': 0.05319148936170213},\n",
      "                             'context_response_rouge': {'rouge1': [0.09523809523809525],\n",
      "                                                        'rouge2': [0.0],\n",
      "                                                        'rougeL': [0.09523809523809525],\n",
      "                                                        'rougeLsum': [0.09523809523809525]},\n",
      "                             'query_response_bertscore': {'f1': [0.8569167256355286],\n",
      "                                                          'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.43.2)',\n",
      "                                                          'precision': [0.8446346521377563],\n",
      "                                                          'recall': [0.8695613145828247]},\n",
      "                             'query_response_bleu': {'bleu': 0.0,\n",
      "                                                     'brevity_penalty': 1.0,\n",
      "                                                     'length_ratio': 3.25,\n",
      "                                                     'precisions': [0.07692307692307693,\n",
      "                                                                    0.0,\n",
      "                                                                    0.0,\n",
      "                                                                    0.0],\n",
      "                                                     'reference_length': 4,\n",
      "                                                     'translation_length': 13},\n",
      "                             'query_response_bleurt': {'scores': [-1.2369744777679443]},\n",
      "                             'query_response_meteor': {'meteor': 0.10204081632653061},\n",
      "                             'query_response_rouge': {'rouge1': [0.125],\n",
      "                                                      'rouge2': [0.0],\n",
      "                                                      'rougeL': [0.125],\n",
      "                                                      'rougeLsum': [0.125]}},\n",
      " 'response_text_stats': {'result_automated_readability_index': 2.0,\n",
      "                         'result_coleman_liau_index': 3.82,\n",
      "                         'result_crawford': -0.8,\n",
      "                         'result_dale_chall_readability_score': 6.57,\n",
      "                         'result_difficult_words': 2,\n",
      "                         'result_fernandez_huerta': 122.72,\n",
      "                         'result_flesch_kincaid_grade': 2.1,\n",
      "                         'result_flesch_reading_ease': 90.77,\n",
      "                         'result_gulpease_index': 95.7,\n",
      "                         'result_gunning_fog': 2.4,\n",
      "                         'result_gutierrez_polini': 51.88,\n",
      "                         'result_linsear_write_formula': 2.0,\n",
      "                         'result_osman': 89.92,\n",
      "                         'result_smog_index': 0.0,\n",
      "                         'result_szigriszt_pazos': 122.96,\n",
      "                         'result_text_standard': '1st and 2nd grade'},\n",
      " 'string_similarities': {'context_response_bm_25_scores': array([-0.27465307]),\n",
      "                         'context_response_fuzz_partial_ratio': 40,\n",
      "                         'context_response_fuzz_partial_token_set_ratio': 100,\n",
      "                         'context_response_fuzz_partial_token_sort_ratio': 50,\n",
      "                         'context_response_fuzz_q_ratio': 40,\n",
      "                         'context_response_fuzz_token_set_ratio': 42,\n",
      "                         'context_response_fuzz_token_sort_ratio': 42,\n",
      "                         'context_response_levenshtein_distance': 47,\n",
      "                         'query_response_bm_25_scores': array([-0.27465307]),\n",
      "                         'query_response_fuzz_partial_ratio': 52,\n",
      "                         'query_response_fuzz_partial_token_set_ratio': 100,\n",
      "                         'query_response_fuzz_partial_token_sort_ratio': 52,\n",
      "                         'query_response_fuzz_q_ratio': 33,\n",
      "                         'query_response_fuzz_token_set_ratio': 38,\n",
      "                         'query_response_fuzz_token_sort_ratio': 38,\n",
      "                         'query_response_levenshtein_distance': 49},\n",
      " 'summarizer_summary': 'these questions and context are bad . there is no '\n",
      "                       'answer .'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41dc7d66685c74bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
